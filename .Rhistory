######## with clustering
setwd("~/Dropbox/Personal computer/Independent studies/2020/Meta-regression metrics (MRM)/Code (git)/Simulation study")
source("helper_MRM.R")
# re-source the updated fns in case of shared names
setwd("~/Dropbox/Personal computer/Independent studies/MetaUtility R package/MetaUtility/R")
source("functions.R")
library(dplyr)
library(ICC)
d = sim_data2(k = 30,
m = 20,
b0 = 0,
bc = 0,
bb = 0,
V = 0.25,
Vzeta = 0.2,
muN = 100,
minN = 50,
sd.w = 1,
true.effect.dist = "normal")
# change cluster name to not be the default inside prop_stronger
names(d)[names(d) == "cluster"] = "paper"
# accounting for clusters: CI = [0%, 61%]
Phat = prop_stronger( q = -0.1,
ci.level = 0.95,
estimate.method = "calibrated",
ci.method = "calibrated",
dat = d,
yi.name = "yi",
vi.name = "vyi",
tail = "below",
cluster.name = "paper")
cluster
cluster.name
datNest = dat %>% group_nest(cluster)
datNest
datNest = dat %>% group_nest(cluster.name)
datNest = dat %>% group_nest(d$cluster)
datNest = dat %>% group_nest(.data$cluster)
datNest
source('~/Dropbox/Personal computer/Independent studies/MetaUtility R package/MetaUtility/R/functions.R', echo=TRUE)
# accounting for clusters: CI = [0%, 61%]
Phat = prop_stronger( q = -0.1,
ci.level = 0.95,
estimate.method = "calibrated",
ci.method = "calibrated",
dat = d,
yi.name = "yi",
vi.name = "vyi",
tail = "below",
cluster.name = "paper")
Phat
check()
check()
d_to_logRR = Vectorize( function( d, se ) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( list(logRR = logRR, varlogRR = varlogRR) )
}, vectorize.args = c("d", "se") }
d_to_logRR = Vectorize( function( d, se ) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( list(logRR = logRR, varlogRR = varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR(.5)
d_to_logRR = Vectorize( function( d, se = NAs) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( list(logRR = logRR, varlogRR = varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR = Vectorize( function( d, se = NA) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( list(logRR = logRR, varlogRR = varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR(.5)
d_to_logRR(.5, .3)
d_to_logRR = Vectorize( function( d, se = NA) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( data.frame(logRR = logRR, varlogRR = varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR(.5, .3)
d_to_logRR = Vectorize( function( d, se = NA) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
return( data.frame(logRR, varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR(.5, .3)
#'         N = 100 )
d_to_logRR = Vectorize( function( d, se = NA) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
browser()
return( data.frame(logRR, varlogRR) )
}, vectorize.args = c("d", "se") )
d_to_logRR(.5, .3)
varlogRR
data.frame(logRR, varlogRR)
#'         N = 100 )
d_to_logRR = function( d, se = NA) {
# simplified the math
# Hasselblad conversion to log-OR followed by TVW's square-root transformation
#  to RR so that we can imagine dichotomizing near median
logRR = log( sqrt( exp( d * pi / sqrt(3) ) ) )
# delta method:
# derivative of log( sqrt( exp(c*d) ) ) wrt d = pi/(2*sqrt(3))
# so squared derivative is pi^2 / 12
varlogRR = ( pi^2 / 12 ) * se^2
browser()
return( data.frame(logRR, varlogRR) )
}
d_to_logRR(.5, .3)
source('~/Dropbox/Personal computer/Independent studies/MetaUtility R package/MetaUtility/R/functions.R', echo=TRUE)
d_to_logRR(.5, .3)
d_to_logRR(.5)
d_to_logRR(c(.5,.4))
d_to_logRR(c(.5,.4), .3)
d_to_logRR(c(.5,.4), c(.3, 2)
)
d_to_logRR(.5, .21)
document()
?d_to_logRR
document()
chekc()
check()
check()
check()
dplyr::unnest
unnest
?unnest
?group_nest
check()
check()
check()
check()
?d_to_logRR
?prop_stronger
document()
?prop_stronger
build()
check()
devtools::check_win_devel()
build()
library(devtools)
check()
document()
build()
check()
check()
13
13/8
5.69/2
library(dplyr)
# turns a vector of Qualtrics completion times (e.g., "8/26/20 7:38") into date objects
dateify = function(x) {
# need to split on space because there are also times in the strings
x2 = strsplit(x, " ")
# keep only the first part (date)
x3 = unlist( lapply(x2, function(.x) .x[[1]]) )
as.Date(x3, "%Y-%m-%d")
}
# dateify("8/26/20 7:38")
setwd("~/Dropbox/Personal computer/Workouts/Workout log (new)/2019")
d = read.csv("data.csv")
d$date = dateify(d$StartDate)
# keep only this week
endDate = as.Date("2021-03-07", "%Y-%m-%d")
d = d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
# sanity check
d$date
length(d$date)
# means
d %>% select( workout, sleep, energy, mood ) %>%
summarise_all( function(x) mean( as.numeric(x) ) )
d$week
d$mood
# workout hrs
d %>% select( cardio, lift ) %>%
summarise_all( function(x) sum( as.numeric(x) ) / 60 )
endDate = as.Date("2021-03-14", "%Y-%m-%d")
d = d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
# sanity check
d$date
length(d$date)
# means
d %>% select( workout, sleep, energy, mood ) %>%
summarise_all( function(x) mean( as.numeric(x) ) )
d
d$EndDate
setwd("~/Dropbox/Personal computer/Workouts/Workout log (new)/2019")
d = read.csv("data.csv")
d$date = dateify(d$StartDate)
d$date
# keep only this week
endDate = as.Date("2021-03-14", "%Y-%m-%d")
d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
d = d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
# sanity check
d$date
length(d$date)
# means
d %>% select( workout, sleep, energy, mood ) %>%
summarise_all( function(x) mean( as.numeric(x) ) )
# workout hrs
d %>% select( cardio, lift ) %>%
summarise_all( function(x) sum( as.numeric(x) ) / 60 )
# mile equivalent
pace = 8.5
sum( as.numeric(d$cardio) ) / pace
check()
library(devtools)
check()
setwd("~/Dropbox/Personal computer/Independent studies/MetaUtility R package/MetaUtility")
check()
build()
check()
document()
build()
check()
build()
check()
check_win()
library(devtools)
check_win()
check_win_devel()
5*9
5*7 + 2*4
.5^3
library(dplyr)
# turns a vector of Qualtrics completion times (e.g., "8/26/20 7:38") into date objects
dateify = function(x) {
# need to split on space because there are also times in the strings
x2 = strsplit(x, " ")
# keep only the first part (date)
x3 = unlist( lapply(x2, function(.x) .x[[1]]) )
as.Date(x3, "%Y-%m-%d")
}
# dateify("8/26/20 7:38")
setwd("~/Dropbox/Personal computer/Workouts/Workout log (new)/2019")
d = read.csv("data.csv")
d$date = dateify(d$StartDate)
# keep only this week
endDate = as.Date("2021-03-14", "%Y-%m-%d")
d = d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
# sanity check
d$date
expect_equal( length(d$date), 7 )
library(testthat)
# turns a vector of Qualtrics completion times (e.g., "8/26/20 7:38") into date objects
dateify = function(x) {
# need to split on space because there are also times in the strings
x2 = strsplit(x, " ")
# keep only the first part (date)
x3 = unlist( lapply(x2, function(.x) .x[[1]]) )
as.Date(x3, "%Y-%m-%d")
}
# dateify("8/26/20 7:38")
setwd("~/Dropbox/Personal computer/Workouts/Workout log (new)/2019")
d = read.csv("data.csv")
d$date = dateify(d$StartDate)
# keep only this week
endDate = as.Date("2021-03-21
", "%Y-%m-%d")
# for taking means of this week
library(dplyr)
library(testthat)
# turns a vector of Qualtrics completion times (e.g., "8/26/20 7:38") into date objects
dateify = function(x) {
# need to split on space because there are also times in the strings
x2 = strsplit(x, " ")
# keep only the first part (date)
x3 = unlist( lapply(x2, function(.x) .x[[1]]) )
as.Date(x3, "%Y-%m-%d")
}
# dateify("8/26/20 7:38")
setwd("~/Dropbox/Personal computer/Workouts/Workout log (new)/2019")
d = read.csv("data.csv")
d$date = dateify(d$StartDate)
# keep only this week
endDate = as.Date("2021-03-21", "%Y-%m-%d")
d = d[ !is.na(d$date) & d$date <= endDate & d$date >= endDate - 6, ]
# sanity check
d$date
expect_equal( length(d$date), 7 )
# means
d %>% select( workout, sleep, energy, mood ) %>%
summarise_all( function(x) mean( as.numeric(x) ) )
# workout hrs
d %>% select( cardio, lift ) %>%
summarise_all( function(x) sum( as.numeric(x) ) / 60 )
# mile equivalent
pace = 8.5
sum( as.numeric(d$cardio) ) / pace
# means
d %>% select( workout, sleep, energy, mood ) %>%
summarise_all( function(x) mean( as.numeric(x) ) )
library(devtools)
check()
r_to_z = function(r) {
if ( any( abs(r) > 1 ) ) stop("Pearson's r cannot be greater than 1 in absolute value")
# handle possible NAs in r vector
z = rep(NA, length(r))
z[ !is.na(r) ] = .5 * ( log(1 + r[ !is.na(r) ]) - log(1 - r[ !is.na(r) ]) )
return(z)
}
r_to_z(.22, -.9, NA)
r_to_z( c(.22, -.9, NA) )
r.not.NA = r[ !is.na(r) ]
r_to_z = function(r) {
r.not.NA = r[ !is.na(r) ]
if ( any( abs(r.not.NA) > 1 ) ) stop("Pearson's r cannot be greater than 1 in absolute value")
# handle possible NAs in r vector
z = rep(NA, length(r))
z[ !is.na(r) ] = .5 * ( log(1 + r.not.NA) - log(1 - r[ !is.na(r.not.NA) ]) )
return(z)
}
r_to_z( c(.22, -.9, NA) )
r_to_z = function(r) {
r.not.NA = r[ !is.na(r) ]
if ( any( abs(r.not.NA) > 1 ) ) stop("Pearson's r cannot be greater than 1 in absolute value")
# handle possible NAs in r vector
z = rep(NA, length(r))
z[ !is.na(r) ] = .5 * ( log(1 + r.not.NA) - log(1 - r.not.NA) )
return(z)
}
r_to_z( c(.22, -.9, NA) )
r_to_z( c(.22, 1.9, NA) )
#' z_to_r(1.1, NA, -0.2)
z_to_r = function(z) {
z.not.NA = z[ !is.na(z) ]
# handle possible NAs in z vector
r = rep(NA, length(z))
r[ !is.na(z) ] = ( exp( 2 * z.not.NA ) - 1 ) / ( exp( 2 * z.not.NA ) + 1 )
return(r)
}
z_to_r(1.1, NA, -0.2)
z_to_r( c(1.1, NA, -0.2) )
d_to_logRR( d = 0.5,
se = 0.21 )
d_to_logRR( d = c(0.5, .1),
se = c(0.21, 0.3) )
d_to_logRR( d = c(0.5, NA, .1),
se = c(0.21, NA,0.3) )
d_to_logRR( d = c(0.5, -0.2, .1),
se = c(0.21, NA, 0.3) )
r_to_d( r = -0.3,
sx = 2,         delta = 2,
N = 300,
Ns = 30 )
r_to_d( r = c(-0.3, 0.2),
sx = 2,         delta = 2,
N = 300,
Ns = 30 )
r_to_d( r = c(-0.3, 0.2),
sx = c(2,1),         delta = c(2,2),
N = c(300, 20),
Ns = c(30, 10) )
r_to_d( r = c(-0.3, NA),
sx = c(2,1),         delta = c(2,2),
N = c(300, 20),
Ns = c(30, 10) )
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA),
df = c(10, NA) )
ci_to_var = Vectorize( function(est,
ci.lim,
ci.level = 0.95,
df = NA){
if ( is.na(est) | is.na(ci.lim) ) return(NA)
# Z or t-stat
stat = abs(est - ci.lim)
if ( is.na(df) ) crit = qnorm(.975)
if ( !is.na(df) ) crit = qt(p = 0.975, df = df)
se = abs(est - ci.lim) / crit
return(se^2)
} )
sanity check
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA),
df = c(10, NA) )
res
expect_equal( 1.05 + qt(.975, df = 10) * sqrt(res[1]), 1.15 )
library(testthat)
expect_equal( 1.05 + qt(.975, df = 10) * sqrt(res[1]), 1.15 )
1-.95
1-.05/2
ci_to_var = Vectorize( function(est,
ci.lim,
ci.level = 0.95,
df = NA){
if ( is.na(est) | is.na(ci.lim) ) return(NA)
# Z or t-stat
stat = abs(est - ci.lim)
alpha = 1 - ci.level
if ( is.na(df) ) crit = qnorm(1 - alpha/2)
if ( !is.na(df) ) crit = qt(p = 1 - alpha/2, df = df)
se = abs(est - ci.lim) / crit
return(se^2)
} )
# sanity check
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA),
df = c(10, NA) )
res
ci_to_var = Vectorize( function(est,
ci.lim,
ci.level = 0.95,
df = NA){
if ( is.na(est) | is.na(ci.lim) ) return(NA)
# Z or t-stat
stat = abs(est - ci.lim)
alpha = 1 - ci.level
if ( is.na(df) ) crit = qnorm(1 - alpha/2)
if ( !is.na(df) ) crit = qt(p = 1 - alpha/2, df = df)
se = abs(est - ci.lim) / crit
return(se^2)
} )
# sanity check
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA), ci.level = c(0.95, .9)
df = c(10, NA) )
ci_to_var = Vectorize( function(est,
ci.lim,
ci.level = 0.95,
df = NA){
if ( is.na(est) | is.na(ci.lim) ) return(NA)
# Z or t-stat
stat = abs(est - ci.lim)
alpha = 1 - ci.level
if ( is.na(df) ) crit = qnorm(1 - alpha/2)
if ( !is.na(df) ) crit = qt(p = 1 - alpha/2, df = df)
se = abs(est - ci.lim) / crit
return(se^2)
} )
# sanity check
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA), ci.level = c(0.95, .9),
df = c(10, NA) )
res
ci_to_var = Vectorize( function(est,
ci.lim,
ci.level = 0.95,
df = NA){
if ( is.na(est) | is.na(ci.lim) ) return(NA)
# Z or t-stat
stat = abs(est - ci.lim)
alpha = 1 - ci.level
if ( is.na(df) ) crit = qnorm(1 - alpha/2)
if ( !is.na(df) ) crit = qt(p = 1 - alpha/2, df = df)
se = abs(est - ci.lim) / crit
return(se^2)
} )
# sanity check
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA), ci.level = c(0.90, .9),
df = c(10, NA) )
res
res = ci_to_var( est = c(1.05, NA),
ci.lim = c(1.15, NA),
df = c(10, NA) )
expect_equal( 1.05 + qt(.975, df = 10) * sqrt(res[1]), 1.15 )
document()
?ci_to_var
document()
?ci_to_var
test()
check()
check()
build()
build()
