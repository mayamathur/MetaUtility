ci.width =  ci.width,
lmer.warning = as.character(lmer.warning),
singular = isSingular(m) ) ) )
}
fake = sim_data( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )
fake$res
fake = replicate(n = 3, sim_data( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials,
doCI = FALSE )$res )
fake
str(fake)
?replicate
unlist(fake)
nsim = 10
for ( i in 1:nsim ) {
row = do_one_dataset( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )$res
if ( i == 1 ) agg = row else agg = rbind( agg, row )
}
# Angeline's parameters
b <- c(1.91, 0.065) # fixed intercept and slope (AT: lower the coefficient estimate to 0.065 to see if the power is still okay for 150 infants)
V1 <- 0.08 # random intercept variance
V2 <- 0.01
s <- 0.11 # residual standard deviation (i.e., 0.33^2)
nsubj = 160
nlab = 10
ntrials = 8  # per subject
do_one_dataset = function(.b,
.V1,
.V2,
.s,
.nsubj,
.nlab,
.ntrials,
doCI = FALSE ) {  # CI profiling is slow
# .b = b
# .V1 = V1
# .V2 = V2
# .s = s
# .nsubj = 160
# .nlab = 10
# .ntrials = 8
# generate fixed parts of dataset
d <- expand.grid(subid = 1:.nsubj,
trial_pair = c(1:.ntrials),
trial_type = c("IDS", "ADS"))
d <- d %>% arrange(subid)
d$trial_num <- rep(c(1:16), each=1, .nsubj)
d$lab <- rep(c(1:.nlab), each = 256)
d$subid <- as.factor(d$subid)
d$trial_type <- as.factor(d$trial_type)
# generate subject intercepts
d = d %>% group_by(subid) %>%
mutate( sint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V1) ) )
##### Generate the Dataset #####
# generate lab intercepts
# we're generating these independently from the subject intercepts,
#  so assuming diagonal correlation matrix of random intercepts
d = d %>% group_by(lab) %>%
mutate( lint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V2) ) )
# # sanity check: should be close
# var( d$sint[ !duplicated( d$subid ) ] ); .V1
# var( d$lint[ !duplicated( d$lab ) ] ); .V2
# linear predictor
d$linpred = .b[1] + d$lint + d$lint +
(.b[2] * (d$trial_type == "IDS") )
d$Y = rnorm( n = nrow(d),
mean = d$linpred,
sd = .s )
# Sanity checks
# library(ggplot2)
#
# ggplot( data = d,
#         aes( x = subid,
#              y = Y,
#              color = as.factor(lab) ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by lab
# ggplot( data = d,
#         aes( x = as.factor(lab),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by subject for first 10 subjects
# ggplot( data = d[ d$subid %in% 1:10, ],
#         aes( x = as.factor(subid),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
##### Analyze the Dataset #####
lmer.warning = NA
tryCatch({
m = lmer( Y ~ trial_type + (1|subid) + (1|lab),
data = d )
#warning("Fake warning")  # to test warning-handling
}, warning = function(warn){
lmer.warning <<- warn
} )
# point estimate for ADS
bhat = fixef(m)["trial_typeADS"]
# inference for ADS
pval = coef(summary(m))["trial_typeADS", "Pr(>|t|)"]
if ( doCI == TRUE ) ci.width = diff( confint(m)["trial_typeADS",] ) else ci.width = NA
##### Return Everything #####
return( list(d = d,
res = data.frame(bhat = bhat,
pval = pval,
ci.width =  ci.width,
lmer.warning = as.character(lmer.warning),
singular = isSingular(m) ) ) )
}
# # sanity check
# fake = do_one_dataset( .b = b,
#                 .V1 = V1,
#                 .V2 = V2,
#                 .s = s,
#                 .nsubj = nsubj,
#                 .nlab = nlab,
#                 .ntrials = ntrials )
# fake$res
nsim = 10
for ( i in 1:nsim ) {
row = do_one_dataset( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )$res
if ( i == 1 ) agg = row else agg = rbind( agg, row )
}
agg
dim(agg)
# Angeline's parameters
b <- c(1.91, 0.065) # fixed intercept and slope (AT: lower the coefficient estimate to 0.065 to see if the power is still okay for 150 infants)
V1 <- 0.08 # random intercept variance
V2 <- 0.01
s <- 0.11 # residual standard deviation (i.e., 0.33^2)
nsubj = 160
nlab = 10
ntrials = 8  # per subject
do_one_dataset = function(.b,
.V1,
.V2,
.s,
.nsubj,
.nlab,
.ntrials,
doCI = FALSE ) {  # CI profiling is slow
# .b = b
# .V1 = V1
# .V2 = V2
# .s = s
# .nsubj = 160
# .nlab = 10
# .ntrials = 8
# generate fixed parts of dataset
d <- expand.grid(subid = 1:.nsubj,
trial_pair = c(1:.ntrials),
trial_type = c("IDS", "ADS"))
d <- d %>% arrange(subid)
d$trial_num <- rep(c(1:16), each=1, .nsubj)
d$lab <- rep(c(1:.nlab), each = 256)
d$subid <- as.factor(d$subid)
d$trial_type <- as.factor(d$trial_type)
# generate subject intercepts
d = d %>% group_by(subid) %>%
mutate( sint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V1) ) )
##### Generate the Dataset #####
# generate lab intercepts
# we're generating these independently from the subject intercepts,
#  so assuming diagonal correlation matrix of random intercepts
d = d %>% group_by(lab) %>%
mutate( lint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V2) ) )
# # sanity check: should be close
# var( d$sint[ !duplicated( d$subid ) ] ); .V1
# var( d$lint[ !duplicated( d$lab ) ] ); .V2
# linear predictor
d$linpred = .b[1] + d$lint + d$lint +
(.b[2] * (d$trial_type == "IDS") )
d$Y = rnorm( n = nrow(d),
mean = d$linpred,
sd = .s )
# Sanity checks
# library(ggplot2)
#
# ggplot( data = d,
#         aes( x = subid,
#              y = Y,
#              color = as.factor(lab) ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by lab
# ggplot( data = d,
#         aes( x = as.factor(lab),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by subject for first 10 subjects
# ggplot( data = d[ d$subid %in% 1:10, ],
#         aes( x = as.factor(subid),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
##### Analyze the Dataset #####
lmer.issue = NA
tryCatch({
m = lmer( Y ~ trial_type + (1|subid) + (1|lab),
data = d )
#warning("Fake warning")  # to test warning-handling
}, warning = function(warn){
lmer.issue <<- warn
}, error = function(err){
lmer.issue <<- err
m <<- NA
} )
if (!is.na(m)) {
# point estimate for ADS
bhat = fixef(m)["trial_typeADS"]
# inference for ADS
pval = coef(summary(m))["trial_typeADS", "Pr(>|t|)"]
if ( doCI == TRUE ) ci.width = diff( confint(m)["trial_typeADS",] ) else ci.width = NA
} else {
bhat = NA
pval = NA
doCI = NA
}
##### Return Everything #####
return( list(d = d,
res = data.frame(bhat = bhat,
pval = pval,
ci.width =  ci.width,
lmer.issue = as.character(lmer.issue),
singular = isSingular(m) ) ) )
}
# # sanity check
# fake = do_one_dataset( .b = b,
#                 .V1 = V1,
#                 .V2 = V2,
#                 .s = s,
#                 .nsubj = nsubj,
#                 .nlab = nlab,
#                 .ntrials = ntrials )
# fake$res
nsim = 10
for ( i in 1:nsim ) {
row = do_one_dataset( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )$res
if ( i == 1 ) agg = row else agg = rbind( agg, row )
}
dim(Agg)
dim(agg)
View(agg)
do_one_dataset = function(.b,
.V1,
.V2,
.s,
.nsubj,
.nlab,
.ntrials,
doCI = FALSE ) {  # CI profiling is slow
# .b = b
# .V1 = V1
# .V2 = V2
# .s = s
# .nsubj = 160
# .nlab = 10
# .ntrials = 8
# generate fixed parts of dataset
d <- expand.grid(subid = 1:.nsubj,
trial_pair = c(1:.ntrials),
trial_type = c("IDS", "ADS"))
d <- d %>% arrange(subid)
d$trial_num <- rep(c(1:16), each=1, .nsubj)
d$lab <- rep(c(1:.nlab), each = 256)
d$subid <- as.factor(d$subid)
d$trial_type <- as.factor(d$trial_type)
# generate subject intercepts
d = d %>% group_by(subid) %>%
mutate( sint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V1) ) )
##### Generate the Dataset #####
# generate lab intercepts
# we're generating these independently from the subject intercepts,
#  so assuming diagonal correlation matrix of random intercepts
d = d %>% group_by(lab) %>%
mutate( lint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V2) ) )
# # sanity check: should be close
# var( d$sint[ !duplicated( d$subid ) ] ); .V1
# var( d$lint[ !duplicated( d$lab ) ] ); .V2
# linear predictor
d$linpred = .b[1] + d$lint + d$lint +
(.b[2] * (d$trial_type == "IDS") )
d$Y = rnorm( n = nrow(d),
mean = d$linpred,
sd = .s )
# Sanity checks
# library(ggplot2)
#
# ggplot( data = d,
#         aes( x = subid,
#              y = Y,
#              color = as.factor(lab) ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by lab
# ggplot( data = d,
#         aes( x = as.factor(lab),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by subject for first 10 subjects
# ggplot( data = d[ d$subid %in% 1:10, ],
#         aes( x = as.factor(subid),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
##### Analyze the Dataset #####
lmer.issue = NA
tryCatch({
m = lmer( Y ~ trial_type + (1|subid) + (1|lab),
data = d )
#warning("Fake warning")  # to test warning-handling
error("Fake error")
}, warning = function(warn){
lmer.issue <<- warn
}, error = function(err){
lmer.issue <<- err
m <<- NA
} )
if (!is.na(m)) {
# point estimate for ADS
bhat = fixef(m)["trial_typeADS"]
# inference for ADS
pval = coef(summary(m))["trial_typeADS", "Pr(>|t|)"]
if ( doCI == TRUE ) ci.width = diff( confint(m)["trial_typeADS",] ) else ci.width = NA
} else {
bhat = NA
pval = NA
doCI = NA
}
##### Return Everything #####
return( list(d = d,
res = data.frame(bhat = bhat,
pval = pval,
ci.width =  ci.width,
lmer.issue = as.character(lmer.issue),
singular = isSingular(m) ) ) )
}
# # sanity check
# fake = do_one_dataset(
debug(do_one_dataset)
# sanity check
fake = do_one_dataset( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )
fake$res
lmer.issue
m
do_one_dataset = function(.b,
.V1,
.V2,
.s,
.nsubj,
.nlab,
.ntrials,
doCI = FALSE ) {  # CI profiling is slow
# .b = b
# .V1 = V1
# .V2 = V2
# .s = s
# .nsubj = 160
# .nlab = 10
# .ntrials = 8
# generate fixed parts of dataset
d <- expand.grid(subid = 1:.nsubj,
trial_pair = c(1:.ntrials),
trial_type = c("IDS", "ADS"))
d <- d %>% arrange(subid)
d$trial_num <- rep(c(1:16), each=1, .nsubj)
d$lab <- rep(c(1:.nlab), each = 256)
d$subid <- as.factor(d$subid)
d$trial_type <- as.factor(d$trial_type)
# generate subject intercepts
d = d %>% group_by(subid) %>%
mutate( sint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V1) ) )
##### Generate the Dataset #####
# generate lab intercepts
# we're generating these independently from the subject intercepts,
#  so assuming diagonal correlation matrix of random intercepts
d = d %>% group_by(lab) %>%
mutate( lint = rnorm( n = 1,
mean = 0,
sd = sqrt(.V2) ) )
# # sanity check: should be close
# var( d$sint[ !duplicated( d$subid ) ] ); .V1
# var( d$lint[ !duplicated( d$lab ) ] ); .V2
# linear predictor
d$linpred = .b[1] + d$lint + d$lint +
(.b[2] * (d$trial_type == "IDS") )
d$Y = rnorm( n = nrow(d),
mean = d$linpred,
sd = .s )
# Sanity checks
# library(ggplot2)
#
# ggplot( data = d,
#         aes( x = subid,
#              y = Y,
#              color = as.factor(lab) ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by lab
# ggplot( data = d,
#         aes( x = as.factor(lab),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
#
# # look at clustering by subject for first 10 subjects
# ggplot( data = d[ d$subid %in% 1:10, ],
#         aes( x = as.factor(subid),
#              y = Y ) ) +
#   geom_violin() +
#   theme_bw()
##### Analyze the Dataset #####
lmer.issue = NA
tryCatch({
m = lmer( Y ~ trial_type + (1|subid) + (1|lab),
data = d )
#warning("Fake warning")  # to test warning-handling
error("Fake error")
}, error = function(err){
lmer.issue <<- err
m <<- NA
}, warning = function(warn){
lmer.issue <<- warn
} )
if (!is.na(m)) {
# point estimate for ADS
bhat = fixef(m)["trial_typeADS"]
# inference for ADS
pval = coef(summary(m))["trial_typeADS", "Pr(>|t|)"]
if ( doCI == TRUE ) ci.width = diff( confint(m)["trial_typeADS",] ) else ci.width = NA
} else {
bhat = NA
pval = NA
doCI = NA
}
##### Return Everything #####
return( list(d = d,
res = data.frame(bhat = bhat,
pval = pval,
ci.width =  ci.width,
lmer.issue = as.character(lmer.issue),
singular = isSingular(m) ) ) )
}
# sanity check
fake = do_one_dataset( .b = b,
.V1 = V1,
.V2 = V2,
.s = s,
.nsubj = nsubj,
.nlab = nlab,
.ntrials = ntrials )
fake$res
